import streamlit as st
import cv2
import numpy as np
from deepface import DeepFace
from PIL import Image
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle
import tempfile
import os

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="EmoScan - An√°lise de Emo√ß√µes com Contexto",
    page_icon="üòä",
    layout="wide"
)

# T√≠tulo e descri√ß√£o
st.title("üòä EmoScan - An√°lise de Emo√ß√µes com Contexto")
st.markdown("""
Este sistema analisa emo√ß√µes humanas considerando o contexto da imagem para uma interpreta√ß√£o mais precisa.
Fa√ßa upload de uma imagem contendo rosto(s) humano(s) para an√°lise.
""")

# Fun√ß√£o para carregar modelo YOLO (simplificado para demonstra√ß√£o)
def load_yolo_context():
    # Em uma implementa√ß√£o real, carregar√≠amos um modelo YOLO pr√©-treinado
    # Para fins de demonstra√ß√£o, usaremos uma abordagem simplificada
    st.success("Modelo de contexto carregado com sucesso!")
    return None

# Fun√ß√£o para detectar contexto (simplificado)
def detect_context(image):
    # Esta √© uma vers√£o simplificada para demonstra√ß√£o
    # Em uma implementa√ß√£o real, usar√≠amos YOLO ou outra rede para detec√ß√£o de objetos
    
    context_items = []
    
    # Simula√ß√£o de detec√ß√£o de contexto baseada em cores e formas simples
    img_array = np.array(image)
    
    # Verificar se h√° tons de azul (poss√≠vel escrit√≥rio)
    blue_dominant = np.mean(img_array[:, :, 2]) > np.mean(img_array[:, :, 1]) + 10
    if blue_dominant:
        context_items.append("escrit√≥rio")
    
    # Verificar se h√° formas retangulares (poss√≠vel eletr√¥nicos)
    gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
    edges = cv2.Canny(gray, 50, 150)
    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    rectangular_objects = 0
    for contour in contours:
        approx = cv2.approxPolyDP(contour, 0.02 * cv2.arcLength(contour, True), True)
        if len(approx) == 4:  # Forma quadrangular
            rectangular_objects += 1
    
    if rectangular_objects > 2:
        context_items.append("dispositivos eletr√¥nicos")
    
    # Verificar tons verdes (poss√≠vel natureza)
    green_dominant = np.mean(img_array[:, :, 1]) > np.mean(img_array[:, :, 0]) + 10
    if green_dominant:
        context_items.append("natureza")
    
    return context_items if context_items else ["contexto indefinido"]

# Fun√ß√£o para ajustar emo√ß√£o com base no contexto
def adjust_emotion(emotion, confidence, context):
    original_emotion = emotion
    original_confidence = confidence
    
    # Regras de ajuste baseadas no contexto
    if "escrit√≥rio" in context and emotion == "sad":
        adjusted_emotion = "concentrado"
        adjusted_confidence = min(95, confidence + 10)
        reason = "Em ambiente de trabalho, express√µes s√©rias s√£o frequentemente concentra√ß√£o"
    
    elif "festa" in context and emotion == "angry":
        adjusted_emotion = "animado"
        adjusted_confidence = min(95, confidence + 5)
        reason = "Em festas, express√µes intensas podem indicar anima√ß√£o"
    
    elif "natureza" in context and emotion == "neutral":
        adjusted_emotion = "pensativo"
        adjusted_confidence = min(95, confidence + 8)
        reason = "Em ambientes naturais, neutralidade pode refletir contempla√ß√£o"
    
    else:
        adjusted_emotion = emotion
        adjusted_confidence = confidence
        reason = "O contexto n√£o alterou significativamente a interpreta√ß√£o da emo√ß√£o"
    
    return {
        "original_emotion": original_emotion,
        "original_confidence": original_confidence,
        "adjusted_emotion": adjusted_emotion,
        "adjusted_confidence": adjusted_confidence,
        "reason": reason
    }

# Fun√ß√£o principal de an√°lise
def analyze_image(image):
    # Salvar imagem temporariamente para processamento
    with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as tmp_file:
        image.save(tmp_file.name)
        img_path = tmp_file.name
    
    try:
        # Detectar rostos e emo√ß√µes com DeepFace
        results = DeepFace.analyze(img_path, actions=['emotion'], enforce_detection=True)
        
        # Detectar contexto
        context = detect_context(image)
        
        # Processar resultados
        analysis_results = []
        for result in results:
            emotion = result['dominant_emotion']
            confidence = result['emotion'][emotion]
            region = result['region']
            
            # Ajustar emo√ß√£o com base no contexto
            adjustment = adjust_emotion(emotion, confidence, context)
            
            analysis_results.append({
                "region": region,
                "adjustment": adjustment,
                "context": context
            })
        
        return analysis_results, None
        
    except Exception as e:
        return None, str(e)
    
    finally:
        # Limpar arquivo tempor√°rio
        os.unlink(img_path)

# Interface principal
uploaded_file = st.file_uploader("Escolha uma imagem...", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    # Carregar e exibir imagem
    image = Image.open(uploaded_file)
    st.image(image, caption="Imagem carregada", use_column_width=True)
    
    # Analisar imagem
    with st.spinner("Analisando imagem..."):
        results, error = analyze_image(image)
    
    if error:
        st.error(f"Erro na an√°lise: {error}")
    else:
        # Exibir resultados
        st.success("An√°lise conclu√≠da!")
        
        for i, result in enumerate(results):
            st.subheader(f"Pessoa {i+1}")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**An√°lise Facial**")
                adjustment = result['adjustment']
                st.metric(
                    label="Emo√ß√£o detectada",
                    value=adjustment['original_emotion'],
                    delta=f"{adjustment['original_confidence']:.1f}%"
                )
            
            with col2:
                st.markdown("**An√°lise Contextual**")
                st.metric(
                    label="Emo√ß√£o ajustada",
                    value=adjustment['adjusted_emotion'],
                    delta=f"{adjustment['adjusted_confidence']:.1f}%"
                )
            
            st.markdown("**Contexto detectado:**")
            st.info(", ".join(result['context']))
            
            st.markdown("**Justificativa do ajuste:**")
            st.write(adjustment['reason'])
            
            st.markdown("---")

# Se√ß√£o de explica√ß√£o do projeto
with st.expander("‚ÑπÔ∏è Sobre este projeto"):
    st.markdown("""
    ## Como funciona este sistema?
    
    Este projeto demonstra um sistema de reconhecimento de emo√ß√µes que considera o contexto da imagem
    para melhorar a precis√£o da an√°lise. A implementa√ß√£o combina:
    
    1. **Detec√ß√£o facial** usando OpenCV atrav√©s da biblioteca DeepFace
    2. **Reconhecimento de emo√ß√µes** usando modelos deep learning pr√©-treinados
    3. **An√°lise de contexto** simplificada para detectar ambiente e objetos
    4. **L√≥gica de ajuste** que modera a emo√ß√£o detectada com base no contexto
    
    ## Tecnologias utilizadas
    
    - Python
    - OpenCV para processamento de imagem
    - DeepFace para an√°lise facial e de emo√ß√µes
    - Streamlit para interface web
    - T√©cnicas de vis√£o computacional para an√°lise contextual simplificada
    
    ## Aplica√ß√µes pr√°ticas
    
    Sistemas como este podem ser aplicados em:
    - An√°lise de satisfa√ß√£o de clientes em lojas
    - Monitoramento de bem-estar em ambientes de trabalho
    - Pesquisas de mercado e an√°lise de comportamento
    - Sistemas de recomenda√ß√£o sens√≠veis ao estado emocional
    """)

# Nota de rodap√©
st.markdown("---")